{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ase.io import read\n",
    "import mpltex\n",
    "from rascal.representations import SphericalInvariants as SOAP\n",
    "from rascal.utils import get_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import Bunch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pylode.projection_coeffs import Density_Projection_Calculator as LODE\n",
    "\n",
    "tab10 = plt.rcParams[\"axes.prop_cycle\"].by_key()['color']\n",
    "kernel_func = partial(polynomial_kernel, gamma=1.0, degree=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kernel_matrix(kernel_func, X, Y, n_atoms, desc=\"Build kernel\"):\n",
    "    \"\"\"Build kernel matrix for kernel ridge regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kernel_func : callable\n",
    "        kernel function. i.e. `sklearn.metrics.pairwise.linear_kernel`\n",
    "    X : ndarray of shape (n_samples_X * n_atoms, n_features)\n",
    "        The first feature array.\n",
    "    Y : ndarray of shape (n_samples_Y * n_atoms, n_features)\n",
    "        The second feature array.\n",
    "    n_atoms : int\n",
    "        Number of atoms in feature. Used to predict number of structures.\n",
    "        `n_structures = len(X)/n_atoms`. Same for `Y`.\n",
    "    desc : str\n",
    "        Description for progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    K : ndarray of shape (n_samples_X, n_samples_Y)\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If predicted number of structures times `n_atoms` is not equal to \n",
    "        the length of one of the feature arrays.\n",
    "    \"\"\"\n",
    "    n_samples_X = len(X) // n_atoms\n",
    "    if n_samples_X * n_atoms != len(X):\n",
    "        raise ValueError(\"X's predicted number of structures does not match!\")\n",
    "\n",
    "    n_samples_Y = len(Y) // n_atoms\n",
    "    if n_samples_Y * n_atoms != len(Y):\n",
    "        raise ValueError(\"Y's predicted number of structures does not match!\")\n",
    "\n",
    "    if X is Y:\n",
    "        # For X==Y the kernel matrix is symmetric.\n",
    "        # Only calculayte upper trangle matrix and copy at the end.\n",
    "        row, col = np.triu_indices(n_samples_X)\n",
    "    else:\n",
    "        row, col = np.indices((n_samples_X, n_samples_Y))\n",
    "\n",
    "    K = np.zeros([n_samples_X, n_samples_Y])\n",
    "\n",
    "    indices = [(r, c) for r, c in zip(row.flatten(),col.flatten())]\n",
    "    for n, m in tqdm(indices, desc=desc):\n",
    "        # Select all atoms in one structure\n",
    "        X_A = X[n * n_atoms:(n + 1) * n_atoms, :]\n",
    "        X_B = X[m * n_atoms:(m + 1) * n_atoms, :]\n",
    "        K[n, m] = np.sum(kernel_func(X_A, X_B))\n",
    "\n",
    "    if X is Y:\n",
    "        K += K.T\n",
    "        K -= np.diag(np.diag(K)) / 2\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_krr(X_reshape, n_features, regularisation=1):\n",
    "    X_train = X_reshape[i_train, :, :]\n",
    "\n",
    "    X_test = X_reshape[i_test, :, :]\n",
    "    X_test = X_test.reshape(n_atoms * n_test, n_features)\n",
    "\n",
    "    rmse_train = np.zeros(len(r_train_structures))\n",
    "    rmse_test = np.zeros(len(r_train_structures))\n",
    "\n",
    "    for i, n_train_structure in enumerate(r_train_structures):\n",
    "        X_train_cur = X_train[:n_train_structure, :]\n",
    "        X_train_cur = X_train_cur.reshape(n_atoms * n_train_structure,\n",
    "                                          n_features)\n",
    "\n",
    "        K_train = build_kernel_matrix(kernel_func,\n",
    "                                      X=X_train_cur,\n",
    "                                      Y=X_train_cur,\n",
    "                                      n_atoms=n_atoms,\n",
    "                                      desc=f\"Build train kernel for\"\n",
    "                                      f\" {n_train_structure} sets\")\n",
    "\n",
    "        K_test = build_kernel_matrix(kernel_func,\n",
    "                                     X=X_test,\n",
    "                                     Y=X_train_cur,\n",
    "                                     n_atoms=n_atoms,\n",
    "                                     desc=f\"Build test kernel for\"\n",
    "                                     f\" {n_train_structure} sets\")\n",
    "\n",
    "        Y_train_cur = Y_train[:n_train_structure]\n",
    "\n",
    "        krr = KernelRidge(alpha=regularisation, kernel=\"precomputed\", gamma=1)\n",
    "        krr.fit(K_train, Y_train_cur)\n",
    "\n",
    "        Y_train_pred = krr.predict(K_train)\n",
    "        Y_test_pred = krr.predict(K_test)\n",
    "\n",
    "        rmse_train[i] = get_score(Y_train_cur, Y_train_pred)[\"RMSE\"]\n",
    "        rmse_test[i] = get_score(Y_test, Y_test_pred)[\"RMSE\"]\n",
    "\n",
    "        # Calculate % RMSE\n",
    "        rmse_train[i] /= Y_train_cur.var()\n",
    "        rmse_test[i] /= Y_train_cur.var()\n",
    "\n",
    "    return rmse_train, rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mpltex.acs_decorator\n",
    "def plot_rmsd(bunch_obj, method_key, prop_key, fname=None):\n",
    "    fmts = [\"-\", \"--\", \".-\"]\n",
    "\n",
    "    results_obj = bunch_obj[method_key]\n",
    "    method = method_key\n",
    "\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "    realiziations = results_obj.keys()\n",
    "    handles_test = len(realiziations) * [None]\n",
    "    handles_train = len(realiziations) * [None]\n",
    "\n",
    "    for i, k in enumerate(realiziations):\n",
    "        label_cutoff = fr\"$r_\\mathrm{{{prop_key}}}=\"\n",
    "        label_cutoff += fr\"{results_obj[k][prop_key]}\\,\\mathrm{{\\AA}}$\"\n",
    "\n",
    "        handles_test[i] = ax.plot(r_train_structures,\n",
    "                                  results_obj[k].rmse_test,\n",
    "                                  fmts[i],\n",
    "                                  c=\"k\",\n",
    "                                  label=rf\"Test, {method}, {label_cutoff}\")[0]\n",
    "\n",
    "        handles_train[i] = ax.plot(\n",
    "            r_train_structures,\n",
    "            results_obj[k].rmse_train,\n",
    "            fmts[i],\n",
    "            c=tab10[0],\n",
    "            label=rf\"Train, {method}, {label_cutoff}\")[0]\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xscale(\"log\")\n",
    "\n",
    "    ax.set_xlim(1e1, 2e3)\n",
    "    ax.set_ylim(1e-2, 1e2)\n",
    "\n",
    "    ax.set_xlabel(\"training structures\")\n",
    "    ax.set_ylabel(\"% RMSE\")\n",
    "\n",
    "    handles = handles_test + handles_train\n",
    "    labels = [handle.get_label() for handle in handles]\n",
    "    ax.legend(handles,\n",
    "              labels,\n",
    "              ncol=2,\n",
    "              handlelength=1,\n",
    "              frameon=True,\n",
    "              edgecolor=\"None\",\n",
    "              fontsize=7)\n",
    "\n",
    "    if fname is not None:\n",
    "        fig.savefig(fname, transparent=True)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../datasets/point_charges_Training_set.xyz\"\n",
    "\n",
    "frames = read(input_file, index=':')\n",
    "n_frames = len(frames)\n",
    "n_atoms = len(frames[0])\n",
    "\n",
    "# Move atoms in unitcell\n",
    "for frame in frames:\n",
    "    frame.wrap()\n",
    "\n",
    "# extract energy\n",
    "Y = np.array([frame.info[\"energy\"] for frame in frames])\n",
    "\n",
    "# Create an object/dictionary for storing results\n",
    "results = Bunch()\n",
    "\n",
    "# Get atomic species in dataset\n",
    "global_species = set()\n",
    "for frame in frames:\n",
    "    global_species.update(frame.get_chemical_symbols())\n",
    "species_dict = {k: i for i, k in enumerate(global_species)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split Train and Test data\n",
    "\n",
    "Here only for Y since the X depends on our applied model (SOAP, LODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = 0.75  # factor of the train set picked from the total set\n",
    "n_subsets = 5  # number of subsets picked on a logspace for scaling test\n",
    "\n",
    "i_train, i_test = train_test_split(np.arange(n_frames),\n",
    "                                   train_size=f_train,\n",
    "                                   random_state=0)\n",
    "n_train = len(i_train)\n",
    "n_test = len(i_test)\n",
    "\n",
    "# Split energies\n",
    "Y_train = Y[i_train]\n",
    "Y_test = Y[i_test]\n",
    "\n",
    "# Generate subsets numbers for training curve\n",
    "exp_max = math.log(n_train, 10)\n",
    "r_train_structures = np.logspace(1, exp_max, num=n_subsets, endpoint=True)\n",
    "r_train_structures = np.round(r_train_structures).astype(int)\n",
    "\n",
    "# Remove doubled values\n",
    "r_train_structures = np.unique(r_train_structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.soap = Bunch()\n",
    "r_cut = [3, 6, 9]\n",
    "regularisation_soap = 10e-3  # From paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cut in r_cut:\n",
    "    results.soap[f\"r_{cut}\"] = Bunch()\n",
    "    results.soap[f\"r_{cut}\"].cut = cut\n",
    "    fname_precomputed = f\"../datasets/precomputed/precomputed_soap_{cut}.npy\"\n",
    "    hypers_soap = dict(\n",
    "        soap_type='PowerSpectrum',  # nu = 2\n",
    "        max_radial=6,\n",
    "        max_angular=6,\n",
    "        gaussian_sigma_type='Constant',\n",
    "        gaussian_sigma_constant=1.0,\n",
    "        cutoff_smooth_width=0.5)\n",
    "\n",
    "    if recalc:\n",
    "        hypers_soap[\"interaction_cutoff\"] = cut\n",
    "\n",
    "        calculator = SOAP(**hypers_soap)\n",
    "        soap_rep = calculator.transform(frames)\n",
    "        X_raw = soap_rep.get_features(calculator)\n",
    "\n",
    "\n",
    "        np.save(fname_precomputed, results.soap[f\"r_{cut}\"].X_raw)\n",
    "\n",
    "    else:\n",
    "        X_raw = np.load(fname_precomputed)\n",
    "\n",
    "    results.soap[f\"r_{cut}\"].X_raw = X_raw\n",
    "\n",
    "    n_features = X_raw.shape[1]\n",
    "    X_reshape = X_raw.reshape(n_frames, n_atoms, n_features)\n",
    "    results.soap[f\"r_{cut}\"].X_reshape = X_reshape\n",
    "    results.soap[f\"r_{cut}\"].n_fetaures = n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train krr model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cut in r_cut:\n",
    "    print(f\"cut = {cut} Å\")\n",
    "\n",
    "    rmse_train, rmse_test = train_predict_krr(\n",
    "        X_reshape=results.soap[f\"r_{cut}\"].X_reshape,\n",
    "        n_features=results.soap[f\"r_{cut}\"].n_fetaures,\n",
    "        regularisation=regularisation_soap)\n",
    "\n",
    "    results.soap[f\"r_{cut}\"].rmse_train = rmse_train.copy()\n",
    "    results.soap[f\"r_{cut}\"].rmse_test = rmse_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmsd(results, \"soap\", \"cut\", fname=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LODE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.lode = Bunch()\n",
    "r_smearing = [3, 2, 1]  # computational cost scales cubically with 1/smearing\n",
    "regularisation_lode = 10e-6  # From paper\n",
    "\n",
    "hypers_lode = dict(\n",
    "    max_angular=2,\n",
    "    cutoff_radius=3,\n",
    "    potential_exponent=1,  # currently, only the exponent p=1 is supported\n",
    "    compute_gradients=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a LONG time if `recalc=True`!\n",
    "for smear in r_smearing:\n",
    "    results.lode[f\"r_{smear}\"] = Bunch()\n",
    "    results.lode[f\"r_{smear}\"].smear = smear\n",
    "    fname_precomputed = f\"../datasets/precomputed/precomputed_lode_{smear}.npy\"\n",
    "    hypers_lode = dict(\n",
    "        max_angular=6,\n",
    "        cutoff_radius=3,\n",
    "        potential_exponent=1,  # currently, only the exponent p=1 is supported\n",
    "        compute_gradients=False)\n",
    "\n",
    "    if recalc:\n",
    "        # TODO: Import function from utilities/precompute_lode.py\n",
    "        hypers_lode[\"smearing\"] = smear\n",
    "\n",
    "        # Get atomic species in dataset\n",
    "        global_species = set()\n",
    "        for frame in frames:\n",
    "            global_species.update(frame.get_chemical_symbols())\n",
    "        species_dict = {k: i for i, k in enumerate(global_species)}\n",
    "\n",
    "        calculator = LODE(**hypers_lode)\n",
    "        lode_rep = calculator.transform(frames, species_dict)\n",
    "        X_raw = lode_rep.get_features(calculator)\n",
    "\n",
    "        np.save(fname_precomputed, results.lode[f\"r_{smear}\"].X_raw)\n",
    "\n",
    "    else:\n",
    "        X_raw = np.load(fname_precomputed)\n",
    "\n",
    "    # reshape lode features in a 2D array - this is common structure\n",
    "    X_raw = X_raw.reshape(X_raw.shape[0], np.prod(X_raw.shape[1:]))\n",
    "    results.lode[f\"r_{smear}\"].X_raw = X_raw\n",
    "\n",
    "    n_features = X_raw.shape[1]\n",
    "    X_reshape = X_raw.reshape(n_frames, n_atoms, n_features)\n",
    "    results.lode[f\"r_{smear}\"].X_reshape = X_reshape\n",
    "    results.lode[f\"r_{smear}\"].n_fetaures = n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for smearing in r_smearing:\n",
    "    print(f\"smearing = {smearing} Å\")\n",
    "\n",
    "    rmse_train, rmse_test = train_predict_krr(\n",
    "        X_reshape=results.lode[f\"r_{smearing}\"].X_reshape,\n",
    "        n_features=results.lode[f\"r_{smear}\"].n_fetaures,\n",
    "        regularisation=regularisation_lode)\n",
    "\n",
    "    results.lode[f\"r_{smear}\"].rmse_train = rmse_train.copy()\n",
    "    results.lode[f\"r_{smear}\"].rmse_test = rmse_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmsd(results, \"lode\", \"smear\", fname=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
